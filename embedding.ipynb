{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNo2rCKW9ZIQRibJsduoHVQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmed-Elbagoury/Problem-Solving-Practice/blob/master/embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is based on https://github.com/rasbt/LLMs-from-scratch/tree/main"
      ],
      "metadata": {
        "id": "CUQgBRKWIYCJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CadizttDpLk5"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQHibp7PwPee",
        "outputId": "98ba8554-8593-466f-f087-1bfed9cfd9ff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken"
      ],
      "metadata": {
        "id": "jlVmpZmEwUul"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataSet(Dataset):\n",
        "\n",
        "    def __init__(self, txt, tokenizer, max_len, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "        for i in range (0, len(token_ids)-max_len, stride):\n",
        "            input_tokens = token_ids[i: i + max_len]\n",
        "            output_tokens = token_ids[i+ 1: i+max_len + 1]\n",
        "            self.input_ids.append(torch.tensor(input_tokens))\n",
        "            self.target_ids.append(torch.tensor(output_tokens))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "    def __getitem__(self, idx):\n",
        "        return {\"input\": self.input_ids[idx], \"target\": self.target_ids[idx]}"
      ],
      "metadata": {
        "id": "YDSyoSDNpPjG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "txt = \"\"\"This is a test text. This is mostly for testing the tokenization only.\n",
        "Later text will test training and inferecne\n",
        "\"\"\"\n",
        "dataset = MyDataSet(txt, tokenizer, 3, 2)"
      ],
      "metadata": {
        "id": "jEphIS-swDis"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ip, op in zip(dataset.input_ids, dataset.target_ids):\n",
        "    print(ip.size(), op.size())\n",
        "    print(f\"'{tokenizer.decode([elem.item() for elem in ip])}'\",\n",
        "          \"-->\",\n",
        "          f\"'{tokenizer.decode([elem.item() for elem in op])}'\")\n",
        "    print(\"-------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hPcYNlhXw0Dz",
        "outputId": "6b0467d2-4418-4960-92dc-38197a8b70c7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3]) torch.Size([3])\n",
            "'This is a' --> ' is a test'\n",
            "-------\n",
            "torch.Size([3]) torch.Size([3])\n",
            "' a test text' --> ' test text.'\n",
            "-------\n",
            "torch.Size([3]) torch.Size([3])\n",
            "' text. This' --> '. This is'\n",
            "-------\n",
            "torch.Size([3]) torch.Size([3])\n",
            "' This is mostly' --> ' is mostly for'\n",
            "-------\n",
            "torch.Size([3]) torch.Size([3])\n",
            "' mostly for testing' --> ' for testing the'\n",
            "-------\n",
            "torch.Size([3]) torch.Size([3])\n",
            "' testing the token' --> ' the tokenization'\n",
            "-------\n",
            "torch.Size([3]) torch.Size([3])\n",
            "' tokenization only' --> 'ization only.'\n",
            "-------\n",
            "torch.Size([3]) torch.Size([3])\n",
            "' only.\n",
            "' --> '.\n",
            "Later'\n",
            "-------\n",
            "torch.Size([3]) torch.Size([3])\n",
            "'\n",
            "Later text' --> 'Later text will'\n",
            "-------\n",
            "torch.Size([3]) torch.Size([3])\n",
            "' text will test' --> ' will test training'\n",
            "-------\n",
            "torch.Size([3]) torch.Size([3])\n",
            "' test training and' --> ' training and inf'\n",
            "-------\n",
            "torch.Size([3]) torch.Size([3])\n",
            "' and infere' --> ' inferec'\n",
            "-------\n",
            "torch.Size([3]) torch.Size([3])\n",
            "'erecne' --> 'cne\n",
            "'\n",
            "-------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader(txt, max_len=256, stride=128, batch_size=4, shuffle=True,\n",
        "                      drop_last=True, num_workers=0):\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "    dataset = MyDataSet(txt, tokenizer, max_len, stride)\n",
        "\n",
        "    return DataLoader(dataset=dataset, batch_size=batch_size,\n",
        "                            shuffle=shuffle,\n",
        "                            drop_last= drop_last,\n",
        "                            num_workers= num_workers)"
      ],
      "metadata": {
        "id": "Ta0Aw334ADlN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "\n",
        "file_path = \"the-verdict.txt\"\n",
        "if not os.path.exists(file_path):\n",
        "    url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
        "           \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
        "           \"the-verdict.txt\")\n",
        "    urllib.request.urlretrieve(url, file_path)"
      ],
      "metadata": {
        "id": "1pidIsYqACxZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(file_path, \"r\") as f:\n",
        "    txt = f.read()"
      ],
      "metadata": {
        "id": "nDJ3i7bvFG9V"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = create_dataloader(txt=txt, max_len=4, stride=1, batch_size=1,\n",
        "                           shuffle=False)"
      ],
      "metadata": {
        "id": "SLf3clT_FFlP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter = iter(loader)\n",
        "first_batch = next(data_iter)\n",
        "print(first_batch[\"input\"])\n",
        "print(first_batch[\"target\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeqFaPtQHLdH",
        "outputId": "c62eac19-d2bc-415c-e25e-916055642c81"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  40,  367, 2885, 1464]])\n",
            "tensor([[ 367, 2885, 1464, 1807]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "second_batch = next(data_iter)\n",
        "print(second_batch[\"input\"])\n",
        "print(second_batch[\"target\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA4FQMQ9GEke",
        "outputId": "70e1905b-650e-4d95-d065-fee49bc381c1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 367, 2885, 1464, 1807]])\n",
            "tensor([[2885, 1464, 1807, 3619]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = create_dataloader(txt=txt, max_len=8, stride=4, batch_size=8,\n",
        "                           shuffle=False)"
      ],
      "metadata": {
        "id": "kT2QDVhWJpch"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter = iter(loader)\n",
        "first_data = next(data_iter)\n",
        "print(\"Inputs:\\n\", first_data[\"input\"])\n",
        "print(\"\\nTargets:\\n\", first_data[\"target\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EXTYdexJzq3",
        "outputId": "28f5b472-5399-4115-860e-793bdaad4e85"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            " tensor([[   40,   367,  2885,  1464,  1807,  3619,   402,   271],\n",
            "        [ 1807,  3619,   402,   271, 10899,  2138,   257,  7026],\n",
            "        [10899,  2138,   257,  7026, 15632,   438,  2016,   257],\n",
            "        [15632,   438,  2016,   257,   922,  5891,  1576,   438],\n",
            "        [  922,  5891,  1576,   438,   568,   340,   373,   645],\n",
            "        [  568,   340,   373,   645,  1049,  5975,   284,   502],\n",
            "        [ 1049,  5975,   284,   502,   284,  3285,   326,    11],\n",
            "        [  284,  3285,   326,    11,   287,   262,  6001,   286]])\n",
            "\n",
            "Targets:\n",
            " tensor([[  367,  2885,  1464,  1807,  3619,   402,   271, 10899],\n",
            "        [ 3619,   402,   271, 10899,  2138,   257,  7026, 15632],\n",
            "        [ 2138,   257,  7026, 15632,   438,  2016,   257,   922],\n",
            "        [  438,  2016,   257,   922,  5891,  1576,   438,   568],\n",
            "        [ 5891,  1576,   438,   568,   340,   373,   645,  1049],\n",
            "        [  340,   373,   645,  1049,  5975,   284,   502,   284],\n",
            "        [ 5975,   284,   502,   284,  3285,   326,    11,   287],\n",
            "        [ 3285,   326,    11,   287,   262,  6001,   286,   465]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding"
      ],
      "metadata": {
        "id": "zrJBz0ZyUVpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 6\n",
        "embedding_dim = 3"
      ],
      "metadata": {
        "id": "zkZ3I7gQUWar"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1234)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5g-apZ_hUiHJ",
        "outputId": "657511f0-39a2-442e-ba53-6118bb958dca"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x79f15c75f010>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = torch.nn.Embedding(vocab_size, embedding_dim)"
      ],
      "metadata": {
        "id": "IoAx8UjPUaYa"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlv8M_rMVCEi",
        "outputId": "8fa9688e-55d1-48b3-b187-bacca2e3d2b1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.1117, -0.4966, -0.7049],\n",
            "        [-1.6024,  0.2891,  0.4899],\n",
            "        [-0.3853, -0.7120,  0.6369],\n",
            "        [-0.7141,  0.2207,  0.2463],\n",
            "        [-1.3248,  0.6970, -0.6631],\n",
            "        [ 1.2158, -2.5273,  1.4778]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer(torch.tensor([3]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiUiV8FGVLnx",
        "outputId": "0424c4cd-8a54-448c-aec8-1e96db937553"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.7141,  0.2207,  0.2463]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = torch.tensor([2, 3, 5, 1])\n",
        "print(embedding_layer(input_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKvBctjIGC4K",
        "outputId": "91822479-e437-4104-a0ba-d73440dcc316"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.3853, -0.7120,  0.6369],\n",
            "        [-0.7141,  0.2207,  0.2463],\n",
            "        [ 1.2158, -2.5273,  1.4778],\n",
            "        [-1.6024,  0.2891,  0.4899]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Positional Embeddins"
      ],
      "metadata": {
        "id": "-JoqaslkHBAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 50257\n",
        "output_dim = 256\n",
        "\n",
        "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
      ],
      "metadata": {
        "id": "poceVmwXHAAN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 4\n",
        "dataloader = create_dataloader(\n",
        "    txt=txt, batch_size=8, max_len=max_length,\n",
        "    stride=max_length, shuffle=False\n",
        ")\n",
        "data_iter = iter(dataloader)\n",
        "element = next(data_iter)"
      ],
      "metadata": {
        "id": "85q87LMIHvpJ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(element.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMZh2nTqIjAw",
        "outputId": "e53f0a6d-3528-4ce5-96f6-377d5cc6e1ec"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['input', 'target'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"inputs\", element[\"input\"])\n",
        "print(\"output\", element[\"target\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEA2GNXEIVXz",
        "outputId": "75adb72d-89ff-4976-f43b-fe456cef33ab"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "output tensor([[  367,  2885,  1464,  1807],\n",
            "        [ 3619,   402,   271, 10899],\n",
            "        [ 2138,   257,  7026, 15632],\n",
            "        [  438,  2016,   257,   922],\n",
            "        [ 5891,  1576,   438,   568],\n",
            "        [  340,   373,   645,  1049],\n",
            "        [ 5975,   284,   502,   284],\n",
            "        [ 3285,   326,    11,   287]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_embeddings = token_embedding_layer(element[\"input\"])\n",
        "output_embeddings = token_embedding_layer(element[\"target\"])"
      ],
      "metadata": {
        "id": "t13_cEn2I51F"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"input_embeddings.shape\", input_embeddings.shape)\n",
        "print(\"output_embeddings.shape\", output_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9c3d7Q7JR2B",
        "outputId": "04039dcb-4ac1-4325-b6d4-735a86a59e09"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_embeddings.shape torch.Size([8, 4, 256])\n",
            "output_embeddings.shape torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = max_length\n",
        "pos_embedding_layer = torch.nn.Embedding(seq_len, output_dim)\n",
        "\n",
        "print(pos_embedding_layer.weight.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot5GEC7HKo5F",
        "outputId": "a62b93cd-52a0-407d-887e-b835bd46940e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_embedding = pos_embedding_layer(torch.arange(max_length))\n",
        "print(pos_embedding.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-vYLu0jLB_N",
        "outputId": "8bb75fb3-cb04-46a4-f7ad-da46ffbc5195"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_embedding = input_embeddings + pos_embedding\n",
        "print(final_embedding.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igC9hH3XLVdz",
        "outputId": "b47bafed-7b3f-40cc-e57d-d175e4498652"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    }
  ]
}